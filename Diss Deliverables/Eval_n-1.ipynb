{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1821f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import self_har_models\n",
    "import pickle\n",
    "import dataset_pre_processing\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import Evaluation1\n",
    "import raw_data_processing\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954982a",
   "metadata": {},
   "source": [
    "# This dataset evaluates the n-1 implementation on each dataset.\n",
    "For the script version of this notebook, see evaluate3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def04084",
   "metadata": {},
   "source": [
    "# LOAD DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e155d18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickled_datasets/pamap2.pickle', 'rb') as file:\n",
    "    pamap_df = pickle.load(file)\n",
    "with open('pickled_datasets/hhar2.pickle', 'rb') as file:\n",
    "    hhar_df = pickle.load(file)\n",
    "with open('pickled_datasets/motionsense2.pickle', 'rb') as file:\n",
    "    motion_sense_df = pickle.load(file)\n",
    "with open('pickled_datasets/harth2.pickle', 'rb') as file:\n",
    "    harth_df = pickle.load(file)\n",
    "with open('pickled_datasets/dasa2.pickle', 'rb') as file:\n",
    "    dasa_df = pickle.load(file)\n",
    "with open('pickled_datasets/wisdm2.pickle', 'rb') as file:\n",
    "    wisdm_df = pickle.load(file)\n",
    "\n",
    "    \n",
    "with open('pickled_datasets/pamap_har.pickle', 'rb') as file:\n",
    "    pamap_har_df = pickle.load(file)\n",
    "with open('pickled_datasets/hhar_har.pickle', 'rb') as file:\n",
    "    hhar_har_df = pickle.load(file)\n",
    "with open('pickled_datasets/motionsense_har.pickle', 'rb') as file:\n",
    "    motionsense_har_df = pickle.load(file)\n",
    "with open('pickled_datasets/harth_har.pickle', 'rb') as file:\n",
    "    harth_har_df = pickle.load(file)\n",
    "with open('pickled_datasets/dasa_har.pickle', 'rb') as file:\n",
    "    dasa_har_df = pickle.load(file)\n",
    "with open('pickled_datasets/wisdm_har.pickle', 'rb') as file:\n",
    "    wisdm_har_df = pickle.load(file)\n",
    "with open('pickled_datasets/wisdm1_har.pickle', 'rb') as file:\n",
    "    wisdm1_har_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c835fb56",
   "metadata": {},
   "source": [
    "# Evaluate PAMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429db9c5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = dataset_pre_processing.concat_datasets([wisdm_df, hhar_df, motion_sense_df, harth_df, dasa_df], 'acc')\n",
    "users = list(df.keys())\n",
    "labels = dataset_pre_processing.get_labels(df)\n",
    "label_map = {label: index for index, label in enumerate(labels)}\n",
    "user_dataset_preprocessed = dataset_pre_processing.pre_process_dataset_composite(\n",
    "    user_datasets=df, \n",
    "    label_map=label_map, \n",
    "    output_shape=31,\n",
    "    train_users=users,\n",
    "    test_users=[],\n",
    "    window_size=400, \n",
    "    shift=200\n",
    ")\n",
    "\n",
    "cm = self_har_models.create_CNN_LSTM_Model((400,3))\n",
    "callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "df = user_dataset_preprocessed\n",
    "composite_model = self_har_models.attach_full_har_classification_head(core_model=cm, \n",
    "                                                                        output_shape=31, \n",
    "                                                                        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0005))\n",
    "history = composite_model.fit(df[0][0], df[0][1]\n",
    "                , epochs=100, validation_data=(df[1][0], df[1][1]), callbacks=[callback])\n",
    "\n",
    "\n",
    "from Evaluation1 import downstream_testing, eval_model\n",
    "har_df = dataset_pre_processing.concat_datasets([pamap_har_df], 'acc')\n",
    "har_users = list(har_df.keys())\n",
    "\n",
    "user_train_size = int(len(har_users)*.8)\n",
    "training_users = har_users[0:(user_train_size)]\n",
    "\n",
    "user_test_size = len(har_users) - user_train_size\n",
    "testing_users = har_users[user_train_size:(user_train_size + user_test_size)]\n",
    "\n",
    "labels = dataset_pre_processing.get_labels(har_df)\n",
    "har_label_map = {label: index for index, label in enumerate(labels)}\n",
    "all_info = []\n",
    "for i in range(3, user_train_size, 1):\n",
    "    har_preprocessed = dataset_pre_processing.pre_process_dataset_composite(\n",
    "    user_datasets=har_df,\n",
    "    label_map=har_label_map,\n",
    "    output_shape=18,\n",
    "    train_users=har_users[0:i],\n",
    "    test_users=testing_users,\n",
    "    window_size=400,\n",
    "    shift=200\n",
    "    )\n",
    "    ds_history, har_model = downstream_testing(har_preprocessed, composite_model, 18, \n",
    "                                            tf.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "    downstream_eval = eval_model(har_preprocessed, labels, har_model)\n",
    "    print(\"Trained \" + str(i) + \" users\")\n",
    "    print(downstream_eval)\n",
    "    info = \"Trained \" + str(i) + \" users \" + str(downstream_eval) \n",
    "    all_info.append(info)\n",
    "\n",
    "print(info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44cc7fa",
   "metadata": {},
   "source": [
    "# HHAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b3ff8b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = dataset_pre_processing.concat_datasets([pamap_df, wisdm_df, motion_sense_df, harth_df, dasa_df], 'acc')\n",
    "users = list(df.keys())\n",
    "labels = dataset_pre_processing.get_labels(df)\n",
    "label_map = {label: index for index, label in enumerate(labels)}\n",
    "user_dataset_preprocessed = dataset_pre_processing.pre_process_dataset_composite(\n",
    "    user_datasets=df, \n",
    "    label_map=label_map, \n",
    "    output_shape=21,\n",
    "    train_users=users,\n",
    "    test_users=[],\n",
    "    window_size=400, \n",
    "    shift=100\n",
    ")\n",
    "\n",
    "cm = self_har_models.create_CNN_LSTM_Model((400,3))\n",
    "callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "df = user_dataset_preprocessed\n",
    "composite_model = self_har_models.attach_full_har_classification_head(core_model=cm, \n",
    "                                                                        output_shape=21, \n",
    "                                                                        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0005))\n",
    "history = composite_model.fit(df[0][0], df[0][1]\n",
    "                , epochs=100, validation_data=(df[1][0], df[1][1]), callbacks=[callback])\n",
    "\n",
    "\n",
    "from Evaluation1 import downstream_testing, eval_model\n",
    "har_df = dataset_pre_processing.concat_datasets([hhar_har_df], 'acc')\n",
    "har_users = list(har_df.keys())\n",
    "\n",
    "user_train_size = int(len(har_users)*.8)\n",
    "training_users = har_users[0:(user_train_size)]\n",
    "\n",
    "user_test_size = len(har_users) - user_train_size\n",
    "testing_users = har_users[user_train_size:(user_train_size + user_test_size)]\n",
    "\n",
    "labels = dataset_pre_processing.get_labels(har_df)\n",
    "har_label_map = {label: index for index, label in enumerate(labels)}\n",
    "all_info = []\n",
    "for i in range(3, user_train_size, 1):\n",
    "    har_preprocessed = dataset_pre_processing.pre_process_dataset_composite(\n",
    "    user_datasets=har_df,\n",
    "    label_map=har_label_map,\n",
    "    output_shape=6,\n",
    "    train_users=har_users[0:i],\n",
    "    test_users=testing_users,\n",
    "    window_size=400,\n",
    "    shift=100\n",
    "    )\n",
    "    ds_history, har_model = downstream_testing(har_preprocessed, composite_model, 6, \n",
    "                                            tf.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "    downstream_eval = eval_model(har_preprocessed, labels, har_model)\n",
    "    print(\"Trained \" + str(i) + \" users\")\n",
    "    print(downstream_eval)\n",
    "    info = \"Trained \" + str(i) + \" users \" + str(downstream_eval) \n",
    "    all_info.append(info)\n",
    "print(\"HHAR\")\n",
    "print(all_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cd58d5",
   "metadata": {},
   "source": [
    "# MOTION SENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514e98e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = dataset_pre_processing.concat_datasets([pamap_df, hhar_df, wisdm_df, harth_df, dasa_df], 'acc')\n",
    "users = list(df.keys())\n",
    "labels = dataset_pre_processing.get_labels(df)\n",
    "label_map = {label: index for index, label in enumerate(labels)}\n",
    "user_dataset_preprocessed = dataset_pre_processing.pre_process_dataset_composite(\n",
    "    user_datasets=df, \n",
    "    label_map=label_map, \n",
    "    output_shape=33,\n",
    "    train_users=users,\n",
    "    test_users=[],\n",
    "    window_size=400, \n",
    "    shift=100\n",
    ")\n",
    "\n",
    "cm = self_har_models.create_CNN_LSTM_Model((400,3))\n",
    "callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "df = user_dataset_preprocessed\n",
    "composite_model = self_har_models.attach_full_har_classification_head(core_model=cm, \n",
    "                                                                        output_shape=33, \n",
    "                                                                        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0005))\n",
    "history = composite_model.fit(df[0][0], df[0][1]\n",
    "                , epochs=100, validation_data=(df[1][0], df[1][1]), callbacks=[callback])\n",
    "\n",
    "\n",
    "from Evaluation1 import downstream_testing, eval_model\n",
    "har_df = dataset_pre_processing.concat_datasets([motionsense_har_df], 'acc')\n",
    "har_users = list(har_df.keys())\n",
    "\n",
    "user_train_size = int(len(har_users)*.8)\n",
    "training_users = har_users[0:(user_train_size)]\n",
    "\n",
    "user_test_size = len(har_users) - user_train_size\n",
    "testing_users = har_users[user_train_size:(user_train_size + user_test_size)]\n",
    "\n",
    "labels = dataset_pre_processing.get_labels(har_df)\n",
    "har_label_map = {label: index for index, label in enumerate(labels)}\n",
    "all_info = []\n",
    "for i in range(3, user_train_size, 2):\n",
    "    har_preprocessed = dataset_pre_processing.pre_process_dataset_composite(\n",
    "    user_datasets=har_df,\n",
    "    label_map=har_label_map,\n",
    "    output_shape=6,\n",
    "    train_users=har_users[0:i],\n",
    "    test_users=testing_users,\n",
    "    window_size=400,\n",
    "    shift=100\n",
    "    )\n",
    "    ds_history, har_model = downstream_testing(har_preprocessed, composite_model, 6, \n",
    "                                            tf.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "    downstream_eval = eval_model(har_preprocessed, labels, har_model)\n",
    "    print(\"Trained \" + str(i) + \" users\")\n",
    "    print(downstream_eval)\n",
    "    info = \"Trained \" + str(i) + \" users \" + str(downstream_eval) \n",
    "    all_info.append(info)\n",
    "print(\"MOTIONSENSE\")\n",
    "print(all_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17054e7a",
   "metadata": {},
   "source": [
    "# HARTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_pre_processing.concat_datasets([hhar_df, wisdm_df, motion_sense_df, pamap_df, dasa_df], 'acc')\n",
    "users = list(df.keys())\n",
    "labels = dataset_pre_processing.get_labels(df)\n",
    "label_map = {label: index for index, label in enumerate(labels)}\n",
    "user_dataset_preprocessed = dataset_pre_processing.pre_process_dataset_composite(\n",
    "    user_datasets=df, \n",
    "    label_map=label_map, \n",
    "    output_shape=22,\n",
    "    train_users=users,\n",
    "    test_users=[],\n",
    "    window_size=400, \n",
    "    shift=100,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "cm = self_har_models.create_CNN_LSTM_Model((400,3))\n",
    "callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "df = user_dataset_preprocessed\n",
    "composite_model = self_har_models.attach_full_har_classification_head(core_model=cm, \n",
    "                                                                        output_shape=22, \n",
    "                                                                        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0005))\n",
    "history = composite_model.fit(df[0][0], df[0][1]\n",
    "                , epochs=100, validation_data=(df[1][0], df[1][1]), callbacks=[callback])\n",
    "\n",
    "\n",
    "from Evaluation1 import downstream_testing, eval_model\n",
    "har_df = dataset_pre_processing.concat_datasets([harth_har_df], 'acc')\n",
    "har_users = list(har_df.keys())\n",
    "\n",
    "user_train_size = int(len(har_users)*.8)\n",
    "training_users = har_users[0:(user_train_size)]\n",
    "\n",
    "user_test_size = len(har_users) - user_train_size\n",
    "testing_users = har_users[user_train_size:(user_train_size + user_test_size)]\n",
    "\n",
    "labels = dataset_pre_processing.get_labels(har_df)\n",
    "har_label_map = {label: index for index, label in enumerate(labels)}\n",
    "all_info = []\n",
    "for i in range(3, user_train_size, 1):\n",
    "    har_preprocessed = dataset_pre_processing.pre_process_dataset_composite(\n",
    "    user_datasets=har_df,\n",
    "    label_map=har_label_map,\n",
    "    output_shape=12,\n",
    "    train_users=har_users[0:i],\n",
    "    test_users=testing_users,\n",
    "    window_size=400,\n",
    "    shift=100\n",
    "    )\n",
    "    ds_history, har_model = downstream_testing(har_preprocessed, composite_model, 12, \n",
    "                                            tf.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "    downstream_eval = eval_model(har_preprocessed, labels, har_model)\n",
    "    print(\"Trained \" + str(i) + \" users\")\n",
    "    print(downstream_eval)\n",
    "    info = \"Trained \" + str(i) + \" users \" + str(downstream_eval) \n",
    "    all_info.append(info)\n",
    "print(\"HARTH\")\n",
    "print(all_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b63afc",
   "metadata": {},
   "source": [
    "# DSAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfad2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_pre_processing.concat_datasets([hhar_df, wisdm_df, motion_sense_df, pamap_df, harth_df], 'acc')\n",
    "users = list(df.keys())\n",
    "labels = dataset_pre_processing.get_labels(df)\n",
    "label_map = {label: index for index, label in enumerate(labels)}\n",
    "user_dataset_preprocessed = dataset_pre_processing.pre_process_dataset_composite(\n",
    "    user_datasets=df, \n",
    "    label_map=label_map, \n",
    "    output_shape=21,\n",
    "    train_users=users,\n",
    "    test_users=[],\n",
    "    window_size=400, \n",
    "    shift=100,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "cm = self_har_models.create_CNN_LSTM_Model((400,3))\n",
    "callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "df = user_dataset_preprocessed\n",
    "composite_model = self_har_models.attach_full_har_classification_head(core_model=cm, \n",
    "                                                                        output_shape=21, \n",
    "                                                                        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0005))\n",
    "history = composite_model.fit(df[0][0], df[0][1]\n",
    "                , epochs=100, validation_data=(df[1][0], df[1][1]), callbacks=[callback])\n",
    "\n",
    "\n",
    "from Evaluation1 import downstream_testing, eval_model\n",
    "har_df = dataset_pre_processing.concat_datasets([dasa_har_df], 'acc')\n",
    "har_users = list(har_df.keys())\n",
    "\n",
    "user_train_size = int(len(har_users)*.8)\n",
    "training_users = har_users[0:(user_train_size)]\n",
    "\n",
    "user_test_size = len(har_users) - user_train_size\n",
    "testing_users = har_users[user_train_size:(user_train_size + user_test_size)]\n",
    "\n",
    "labels = dataset_pre_processing.get_labels(har_df)\n",
    "har_label_map = {label: index for index, label in enumerate(labels)}\n",
    "all_info = []\n",
    "for i in range(3, user_train_size, 1):\n",
    "    har_preprocessed = dataset_pre_processing.pre_process_dataset_composite(\n",
    "    user_datasets=har_df,\n",
    "    label_map=har_label_map,\n",
    "    output_shape=19,\n",
    "    train_users=har_users[0:i],\n",
    "    test_users=testing_users,\n",
    "    window_size=400,\n",
    "    shift=10\n",
    "    )\n",
    "    ds_history, har_model = downstream_testing(har_preprocessed, composite_model, 19, \n",
    "                                            tf.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "    downstream_eval = eval_model(har_preprocessed, labels, har_model)\n",
    "    print(\"Trained \" + str(i) + \" users\")\n",
    "    print(downstream_eval)\n",
    "    info = \"Trained \" + str(i) + \" users \" + str(downstream_eval) \n",
    "    all_info.append(info)\n",
    "print(\"DASD\")\n",
    "print(all_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2472039d",
   "metadata": {},
   "source": [
    "# WISDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickled_datasets/wisdm1_har.pickle', 'rb') as file:\n",
    "    wisdm1_har_df = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f33bd57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = dataset_pre_processing.concat_datasets([pamap_df, hhar_df, motion_sense_df, harth_df, dasa_df], 'acc')\n",
    "users = list(df.keys())\n",
    "labels = dataset_pre_processing.get_labels(df)\n",
    "label_map = {label: index for index, label in enumerate(labels)}\n",
    "user_dataset_preprocessed = dataset_pre_processing.pre_process_dataset_composite(\n",
    "    user_datasets=df, \n",
    "    label_map=label_map, \n",
    "    output_shape=22,\n",
    "    train_users=users,\n",
    "    test_users=[],\n",
    "    window_size=400, \n",
    "    shift=100\n",
    ")\n",
    "\n",
    "cm = self_har_models.create_CNN_LSTM_Model((400,3))\n",
    "callback = tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "df = user_dataset_preprocessed\n",
    "composite_model = self_har_models.attach_full_har_classification_head(core_model=cm, \n",
    "                                                                        output_shape=22, \n",
    "                                                                        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0005))\n",
    "history = composite_model.fit(df[0][0], df[0][1]\n",
    "                , epochs=100, validation_data=(df[1][0], df[1][1]), callbacks=[callback])\n",
    "\n",
    "\n",
    "from Evaluation1 import downstream_testing, eval_model\n",
    "har_df = dataset_pre_processing.concat_datasets([wisdm1_har_df], 'acc')\n",
    "har_users = list(har_df.keys())\n",
    "\n",
    "user_train_size = int(len(har_users)*.8)\n",
    "training_users = har_users[0:(user_train_size)]\n",
    "\n",
    "user_test_size = len(har_users) - user_train_size\n",
    "testing_users = har_users[user_train_size:(user_train_size + user_test_size)]\n",
    "\n",
    "labels = dataset_pre_processing.get_labels(har_df)\n",
    "har_label_map = {label: index for index, label in enumerate(labels)}\n",
    "all_info = []\n",
    "for i in range(3, user_train_size, 2):\n",
    "    har_preprocessed = dataset_pre_processing.pre_process_dataset_composite(\n",
    "    user_datasets=har_df,\n",
    "    label_map=har_label_map,\n",
    "    output_shape=6,\n",
    "    train_users=har_users[0:i],\n",
    "    test_users=testing_users,\n",
    "    window_size=400,\n",
    "    shift=100\n",
    "    )\n",
    "    ds_history, har_model = downstream_testing(har_preprocessed, composite_model, 6, \n",
    "                                            tf.keras.optimizers.Adam(learning_rate=0.0005))\n",
    "    downstream_eval = eval_model(har_preprocessed, labels, har_model)\n",
    "    print(\"Trained \" + str(i) + \" users\")\n",
    "    print(downstream_eval)\n",
    "    info = \"Trained \" + str(i) + \" users \" + str(downstream_eval) \n",
    "    all_info.append(info)\n",
    "print(\"WISDM\")\n",
    "print(all_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
